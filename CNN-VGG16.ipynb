{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYVb9gw9HrgH",
        "outputId": "49c46d75-eae3-4011-dc5b-cf8be34e48f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def save_model(epoch):\n",
        "\n",
        "  path = f\"./model_epoch_{epoch}.pth\"\n",
        "  torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "nmgsDEKTu7Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/cropped/cropped'"
      ],
      "metadata": {
        "id": "2rsVMaHKItDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os\n",
        "import re"
      ],
      "metadata": {
        "id": "yjT0QwZZI8aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "\n",
        "#train_labels\n",
        "csv_file_path = 'labels.csv'\n",
        "# And corresponding images\n",
        "images_path = path\n",
        "\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "TO14XJzTZVid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.iloc[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMVpoFAacllD",
        "outputId": "f9a6a68a-ea6e-41d7-8bfd-445313d8e548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                        2\n",
            "label                     1\n",
            "source_img    train_673.png\n",
            "Name: 2, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, image_dir, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.dataframe.iloc[idx, 0]\n",
        "        label = self.dataframe.iloc[idx, 1]\n",
        "\n",
        "        img_path = f'{self.image_dir}/{img_name}.png'\n",
        "        image = Image.open(img_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "k5BFBN7fZn7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.1)\n",
        "\n",
        "# Create the dataset\n",
        "train_dataset = CustomDataset(dataframe=train_df, image_dir=images_path, transform=transform)\n",
        "test_dataset = CustomDataset(dataframe=test_df, image_dir=images_path, transform=transform)\n",
        "\n",
        "\n",
        "# Create the DataLoader\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "RfLIlEp4bGaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "num_classes = 4\n",
        "\n",
        "model = models.vgg16(pretrained=True)\n",
        "# Freeze the features layers (optional, depending on your needs)\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the classifier\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n1Ow3UPdOUy",
        "outputId": "900c328f-4305-49ba-84d8-1f4187b7a2c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:04<00:00, 137MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.classifier.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "ACRfKflGelyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "num_epochs = 10\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def validation_metrics(model, dataloader, device, criterion):\n",
        "    model.eval()\n",
        "    validation_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            validation_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_validation_loss = validation_loss / len(dataloader)\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy, avg_validation_loss\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    training_accuracy = 100 * correct / total\n",
        "\n",
        "    validation_accuracy, validation_loss = validation_metrics(model, test_loader, device, criterion)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Training Accuracy: {training_accuracy:.2f}%')\n",
        "    print(f'Validation Accuracy: {validation_accuracy:.2f}%, Validation Loss: {validation_loss:.4f}')\n",
        "\n",
        "    save_model(epoch)"
      ],
      "metadata": {
        "id": "a6K8y1riel1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1490ce8f-e654-484e-89c4-c02ea28f69c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.9023, Training Accuracy: 67.47%\n",
            "Validation Accuracy: 72.24%, Validation Loss: 0.7378\n",
            "Epoch 2/10, Loss: 0.7473, Training Accuracy: 72.73%\n",
            "Validation Accuracy: 75.07%, Validation Loss: 0.6694\n",
            "Epoch 3/10, Loss: 0.6810, Training Accuracy: 74.28%\n",
            "Validation Accuracy: 74.79%, Validation Loss: 0.6335\n",
            "Epoch 4/10, Loss: 0.6283, Training Accuracy: 75.63%\n",
            "Validation Accuracy: 76.77%, Validation Loss: 0.6096\n",
            "Epoch 5/10, Loss: 0.5822, Training Accuracy: 78.09%\n",
            "Validation Accuracy: 76.77%, Validation Loss: 0.5929\n",
            "Epoch 6/10, Loss: 0.5452, Training Accuracy: 78.90%\n",
            "Validation Accuracy: 76.77%, Validation Loss: 0.5965\n",
            "Epoch 7/10, Loss: 0.4994, Training Accuracy: 79.85%\n",
            "Validation Accuracy: 77.05%, Validation Loss: 0.5743\n",
            "Epoch 8/10, Loss: 0.4592, Training Accuracy: 81.71%\n",
            "Validation Accuracy: 76.77%, Validation Loss: 0.5912\n",
            "Epoch 9/10, Loss: 0.4094, Training Accuracy: 83.88%\n",
            "Validation Accuracy: 72.52%, Validation Loss: 0.6109\n",
            "Epoch 10/10, Loss: 0.3660, Training Accuracy: 86.37%\n",
            "Validation Accuracy: 76.49%, Validation Loss: 0.5597\n"
          ]
        }
      ]
    }
  ]
}